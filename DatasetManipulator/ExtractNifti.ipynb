{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68b987b6-f3cf-4b70-abd4-783f5121ef21",
   "metadata": {},
   "source": [
    "# Extract data from nifty image files to bmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9472591d-1bf3-4168-8d60-3af17774fbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torchvision.transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f375c6-3ac0-4192-83a2-3cb069b1bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"G:/MachineLearning/training-batch-1/testing/\"\n",
    "image_files = sorted(glob.glob(root_dir + 'volume*.nii'))\n",
    "mask_files = sorted(glob.glob(root_dir + 'segmentation*.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "105ff1e4-ac8e-40c0-a967-6c52c653a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"G:/MachineLearning/liver-database/validation/\"\n",
    "\n",
    "window_min = -250\n",
    "window_max = 250\n",
    "\n",
    "downsample = torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.ToPILImage(),\n",
    "         torchvision.transforms.Resize(256, interpolation=torchvision.transforms.InterpolationMode.BILINEAR, antialias=True),\n",
    "         torchvision.transforms.ToTensor()]\n",
    "    )\n",
    "downsample_mask = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToPILImage(),\n",
    "     torchvision.transforms.Resize(256, interpolation=torchvision.transforms.InterpolationMode.NEAREST),\n",
    "     torchvision.transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "num_img = len(image_files)\n",
    "for i in range(num_img):\n",
    "    image = nib.load(image_files[i])\n",
    "    data = image.get_fdata()\n",
    "    num_slices = data.shape[2] # 512 x 512 x num_slices\n",
    "    for j in range(num_slices):\n",
    "        slc = data[:, :, j]\n",
    "        slc[slc < window_min] = window_min\n",
    "        slc[slc > window_max] = window_max\n",
    "        slc = (slc - window_min) / (window_max - window_min)\n",
    "        # slc = downsample(slc.astype(np.float32)).numpy()\n",
    "        slc.astype(np.float16).tofile(out_dir + \"images/\" + os.path.splitext(os.path.basename(image_files[i]))[0] + (\"-%04d.ct\" % j))\n",
    "\n",
    "        \n",
    "num_img = len(mask_files)\n",
    "for i in range(num_img):\n",
    "    image = nib.load(mask_files[i])\n",
    "    data = image.get_fdata()\n",
    "    num_slices = data.shape[2] # 512 x 512 x num_slices\n",
    "    for j in range(num_slices):\n",
    "        slc = data[:, :, j]\n",
    "        # slc = downsample_mask(slc.astype(np.float32)).numpy()\n",
    "        slc.astype(np.float16).tofile(out_dir + \"masks/\" + os.path.splitext(os.path.basename(mask_files[i]))[0] + (\"-%04d.ct\" % j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a921d0-6dc5-4c8b-a36c-c10d727e6aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLEnv] *",
   "language": "python",
   "name": "conda-env-MLEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}